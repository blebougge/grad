# readItems - no arg
{'and': 'AND_LG', 'int': 'INTEGER', 'ary': 'ARRAY_DECLARATION', 'eq': 'EQUAL_LG', 'if': 'CONDITIONAL', '#': 'COMMENT', 'end': 'END_BRACKET', ')': 'END_PAR', '(': 'START_PAR', 'fix': 'CONST_VAR', '*': 'MULT_OP', '-': 'MINUS_OP', ',': 'COMMA', '/': 'DIV_OP', 'write': 'WRITE_FUNC', 'read': 'READ_FUNC', 'prog': 'PROG_DEF', ';': 'IDENT', ':': 'DEFINITION', '=': 'EQUAL_OP', '>': 'GREATER_LG', 'begin': 'START_BRACKET', '!=': 'NOT_EQUAL_LG', 'bl': 'BOOLEAN', 'not': 'NOT_LG', 'dob': 'DOUBLE', 'or': 'OR_LG', 'while': 'LOOP', 'str': 'STRING', '+': 'SUM_OP'}
# readItems - correct use
{'and': 'AND_LG', 'int': 'INTEGER', 'ary': 'ARRAY_DECLARATION', 'eq': 'EQUAL_LG', 'if': 'CONDITIONAL', '#': 'COMMENT', 'end': 'END_BRACKET', ')': 'END_PAR', '(': 'START_PAR', 'fix': 'CONST_VAR', '*': 'MULT_OP', '-': 'MINUS_OP', ',': 'COMMA', '/': 'DIV_OP', 'write': 'WRITE_FUNC', 'read': 'READ_FUNC', 'prog': 'PROG_DEF', ';': 'IDENT', ':': 'DEFINITION', '=': 'EQUAL_OP', '>': 'GREATER_LG', 'begin': 'START_BRACKET', '!=': 'NOT_EQUAL_LG', 'bl': 'BOOLEAN', 'not': 'NOT_LG', 'dob': 'DOUBLE', 'or': 'OR_LG', 'while': 'LOOP', 'str': 'STRING', '+': 'SUM_OP'}

# tokenizer - lang.items lexars
{0: '<prog, PROG_DEF>', 1: '<PROG_DEF, ???>', 2: '<;, IDENT>', 3: '<begin, START_BRACKET>', 4: '<START_BRACKET, ???>', 5: '<;, IDENT>', 6: '<end, END_BRACKET>', 7: '<END_BRACKET, ???>', 8: '<;, IDENT>', 9: '<fix, CONST_VAR>', 10: '<CONST_VAR, ???>', 11: '<;, IDENT>', 12: '<ary, ARRAY_DECLARATION>', 13: '<ARRAY_DECLARATION, ???>', 14: '<;, IDENT>', 15: '<:, DEFINITION>', 16: '<DEFINITION, ???>', 17: '<;, IDENT>', 18: '<(, START_PAR>', 19: '<START_PAR, ???>', 20: '<;, IDENT>', 21: '<), END_PAR>', 22: '<END_PAR, ???>', 23: '<;, IDENT>', 24: '<# COMMENT, COMMENT>', 25: '<;, IDENT>', 26: '<,, COMMA>', 27: '<COMMA, ???>', 28: '<;, IDENT>', 29: '<int, INTEGER>', 30: '<INTEGER, ???>', 31: '<;, IDENT>', 32: '<dob, DOUBLE>', 33: '<DOUBLE, ???>', 34: '<;, IDENT>', 35: '<bl, BOOLEAN>', 36: '<BOOLEAN, ???>', 37: '<;, IDENT>', 38: '<str, STRING>', 39: '<STRING, ???>', 40: '<;, IDENT>', 41: '<while, LOOP>', 42: '<LOOP, ???>', 43: '<;, IDENT>', 44: '<if, CONDITIONAL>', 45: '<CONDITIONAL, ???>', 46: '<;, IDENT>', 47: '<read, READ_FUNC>', 48: '<READ_FUNC, ???>', 49: '<;, IDENT>', 50: '<write, WRITE_FUNC>', 51: '<WRITE_FUNC, ???>', 52: '<;, IDENT>', 53: '<+, SUM_OP>', 54: '<SUM_OP, ???>', 55: '<;, IDENT>', 56: '<-, MINUS_OP>', 57: '<MINUS_OP, ???>', 58: '<;, IDENT>', 59: '<*, MULT_OP>', 60: '<MULT_OP, ???>', 61: '<;, IDENT>', 62: '</, DIV_OP>', 63: '<DIV_OP, ???>', 64: '<;, IDENT>', 65: '<=, EQUAL_OP>', 66: '<EQUAL_OP, ???>', 67: '<;, IDENT>', 68: '<>, GREATER_LG>', 69: '<GREATER_LG, ???>', 70: '<;, IDENT>', 71: '<eq, EQUAL_LG>', 72: '<EQUAL_LG, ???>', 73: '<;, IDENT>', 74: '<!, ???>', 75: '<=, EQUAL_OP>', 76: '<NOT_EQUAL_LG, ???>', 77: '<;, IDENT>', 78: '<not, NOT_LG>', 79: '<NOT_LG, ???>', 80: '<;, IDENT>', 81: '<and, AND_LG>', 82: '<AND_LG, ???>', 83: '<;, IDENT>', 84: '<or, OR_LG>', 85: '<OR_LG, ???>', 86: '<;, IDENT>', 87: '<;, IDENT>', 88: '<IDENT, ???>', 89: '<;, IDENT>'}
# tokenizer - langError.in lexars
{0: '<# caian 05/11/2015, COMMENT>', 1: '<;, IDENT>', 2: '<pro, ???>', 3: '<lang.in, ???>', 4: '<;, IDENT>', 5: '<fix, CONST_VAR>', 6: '<int, INTEGER>', 7: '<:, DEFINITION>', 8: '<id, ???>', 9: '<=, EQUAL_OP>', 10: '<1, ???>', 11: '<;, IDENT>', 12: '<fi, ???>', 13: '<st, ???>', 14: '<:, DEFINITION>', 15: '<.out, ???>', 16: '<=, EQUAL_OP>', 17: '<"file_name, ???>', 18: '<;, IDENT>', 19: '<begin, START_BRACKET>', 20: '<;, IDENT>', 21: '<int, INTEGER>', 22: '<:, DEFINITION>', 23: '<x, ???>', 24: '<=, EQUAL_OP>', 25: '<2, ???>', 26: '<;, IDENT>', 27: '<x, ???>', 28: '<x, ???>', 29: '<+, SUM_OP>', 30: '<id, ???>', 31: '<;, IDENT>', 32: '<if, CONDITIONAL>', 33: '<(, START_PAR>', 34: '<x, ???>', 35: '<2, ???>', 36: '<), END_PAR>', 37: '<;, IDENT>', 38: '<begin, START_BRACKET>', 39: '<;, IDENT>', 40: '<wrie, ???>', 41: '<(, START_PAR>', 42: '<ile_name, ???>', 43: '<,, COMMA>', 44: '<x, ???>', 45: '<), END_PAR>', 46: '<;, IDENT>', 47: '<end, END_BRACKET>', 48: '<;, IDENT>', 49: '<str, STRING>', 50: '<:, DEFINITION>', 51: '<file, ???>', 52: '<;, IDENT>', 53: '<if, CONDITIONAL>', 54: '<eq, EQUAL_LG>', 55: '<2, ???>', 56: '<), END_PAR>', 57: '<;, IDENT>', 58: '<bein, ???>', 59: '<;, IDENT>', 60: '<file, ???>', 61: '<=, EQUAL_OP>', 62: '<read, READ_FUNC>', 63: '<(, START_PAR>', 64: '<file_ame, ???>', 65: '<;, IDENT>', 66: '<en, ???>', 67: '<;, IDENT>', 68: '<end, END_BRACKET>', 69: '<;, IDENT>'}
# tokenizer - lang.in lexars
{0: '<# caian 05/11/2015, COMMENT>', 1: '<;, IDENT>', 2: '<prog, PROG_DEF>', 3: '<lang.in, ???>', 4: '<;, IDENT>', 5: '<fix, CONST_VAR>', 6: '<int, INTEGER>', 7: '<:, DEFINITION>', 8: '<id, ???>', 9: '<=, EQUAL_OP>', 10: '<1, ???>', 11: '<;, IDENT>', 12: '<fix, CONST_VAR>', 13: '<str, STRING>', 14: '<:, DEFINITION>', 15: '<f.out, ???>', 16: '<=, EQUAL_OP>', 17: '<"file_name", ???>', 18: '<;, IDENT>', 19: '<begin, START_BRACKET>', 20: '<;, IDENT>', 21: '<int, INTEGER>', 22: '<:, DEFINITION>', 23: '<x, ???>', 24: '<=, EQUAL_OP>', 25: '<2, ???>', 26: '<;, IDENT>', 27: '<x, ???>', 28: '<=, EQUAL_OP>', 29: '<x, ???>', 30: '<+, SUM_OP>', 31: '<id, ???>', 32: '<;, IDENT>', 33: '<if, CONDITIONAL>', 34: '<(, START_PAR>', 35: '<x, ???>', 36: '<>, GREATER_LG>', 37: '<2, ???>', 38: '<), END_PAR>', 39: '<;, IDENT>', 40: '<begin, START_BRACKET>', 41: '<;, IDENT>', 42: '<write, WRITE_FUNC>', 43: '<(, START_PAR>', 44: '<file_name, ???>', 45: '<,, COMMA>', 46: '<x, ???>', 47: '<), END_PAR>', 48: '<;, IDENT>', 49: '<end, END_BRACKET>', 50: '<;, IDENT>', 51: '<str, STRING>', 52: '<:, DEFINITION>', 53: '<file, ???>', 54: '<;, IDENT>', 55: '<if, CONDITIONAL>', 56: '<(, START_PAR>', 57: '<x, ???>', 58: '<eq, EQUAL_LG>', 59: '<2, ???>', 60: '<), END_PAR>', 61: '<;, IDENT>', 62: '<begin, START_BRACKET>', 63: '<;, IDENT>', 64: '<file, ???>', 65: '<=, EQUAL_OP>', 66: '<read, READ_FUNC>', 67: '<(, START_PAR>', 68: '<file_name, ???>', 69: '<), END_PAR>', 70: '<;, IDENT>', 71: '<end, END_BRACKET>', 72: '<;, IDENT>', 73: '<end, END_BRACKET>', 74: '<;, IDENT>'}
